{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why you picked this data where you got it( intro slide) \n",
    "look at some of images (typical for class 1 and class 2 ) \n",
    "feature extraction (not required but you can use https://scikit-learn.org/stable/modules/feature_extraction.html) \n",
    "to explicitly get features to understand what are the features making up class 1 etc \n",
    "then model fitting \n",
    "you can have a table of all models fitted with the accuracy score, precision, recall f1 \n",
    "and discuss which one is winning (is type 1 worse than type 2 etc) \n",
    "then print out some examples where your model is making correct pred and incorrect pred \n",
    "then conclusions/next steps \n",
    "so in total you can have 10 slides for this\n",
    "with some appendix if you want \n",
    "lastly models that we can try can be\n",
    "\n",
    "4. keras conv2d more complex \n",
    "5 transfer learning from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "import glob\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for directory, _, file in os.walk('data/chest_xray/train'):\n",
    "    for f in file[1::4]:\n",
    "        f = os.path.join(directory, f)\n",
    "        img = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = resize(img, (150, 150, 1))\n",
    "            img = np.asarray(img)\n",
    "            label=f.split('/')[-2]\n",
    "            X.append(img)\n",
    "            y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "for directory, _, file in os.walk('data/chest_xray/test'):\n",
    "    for f in file[1:]:\n",
    "        f = os.path.join(directory, f)\n",
    "        img = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = resize(img, (150, 150, 1))\n",
    "            img = np.asarray(img)\n",
    "            label=f.split('/')[-2]\n",
    "            X_test.append(img)\n",
    "            y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)\n",
    "X_test = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf = []\n",
    "for i in range(len(X)):\n",
    "    a = X[i].flatten()\n",
    "    X_rf.append(a)\n",
    "    \n",
    "X_rf = np.asarray(X_rf)\n",
    "\n",
    "X_rf_test = []\n",
    "for i in range(len(X_test)):\n",
    "    a = X_test[i].flatten()\n",
    "    X_rf_test.append(a)\n",
    "    \n",
    "X_rf_test = np.asarray(X_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1305"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91034483 0.91264368 0.93563218]\n"
     ]
    }
   ],
   "source": [
    "rf = ensemble.RandomForestClassifier()\n",
    "rf.fit(X_rf, y)\n",
    "print(cross_val_score(rf, X_rf, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 81, 152],\n",
       "       [ 12, 377]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(X_rf_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=.2,\n",
    "        height_shift_range=.2,\n",
    "        rescale=1/255,\n",
    "        shear_range=.2,\n",
    "        zoom_range=.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, 150, 150)\n",
    "else:\n",
    "    input_shape = (150, 150, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = datagen.flow_from_directory('data/chest_xray/train',\n",
    "                                   target_size=(150, 150),\n",
    "                                   batch_size=16,\n",
    "                                   class_mode='binary')\n",
    "\n",
    "test = test_datagen.flow_from_directory('data/chest_xray/test',\n",
    "                                   target_size=(150, 150),\n",
    "                                   batch_size=16,\n",
    "                                   class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "326/326 [==============================] - 104s 318ms/step - loss: 4.0974 - acc: 0.7391 - val_loss: 5.9585 - val_acc: 0.6262\n",
      "Epoch 2/2\n",
      "326/326 [==============================] - 101s 310ms/step - loss: 4.0975 - acc: 0.7421 - val_loss: 6.0780 - val_acc: 0.6188\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train,\n",
    "                   steps_per_epoch=5216 // 16,\n",
    "                   epochs = 20,\n",
    "                   validation_data = test,\n",
    "                   validation_steps=800 // 16)\n",
    "model.save_weights('weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "39/39 [==============================] - 5s 122ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.978394545041597, 0.625]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "train = datagen.flow_from_directory('data/chest_xray/train',\n",
    "                                   target_size=(150, 150),\n",
    "                                   batch_size=16,\n",
    "                                   class_mode='binary')\n",
    "\n",
    "test = test_datagen.flow_from_directory('data/chest_xray/test',\n",
    "                                   target_size=(150, 150),\n",
    "                                   batch_size=16,\n",
    "                                   class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "326/326 [==============================] - 151s 462ms/step - loss: 0.4081 - acc: 0.8127 - val_loss: 1.2687 - val_acc: 0.5625\n",
      "Epoch 2/20\n",
      "326/326 [==============================] - 147s 452ms/step - loss: 0.3903 - acc: 0.8252 - val_loss: 0.7855 - val_acc: 0.6875\n",
      "Epoch 3/20\n",
      "326/326 [==============================] - 147s 450ms/step - loss: 0.3822 - acc: 0.8344 - val_loss: 0.7314 - val_acc: 0.8125\n",
      "Epoch 4/20\n",
      "326/326 [==============================] - 141s 431ms/step - loss: 0.3328 - acc: 0.8585 - val_loss: 0.5688 - val_acc: 0.8125\n",
      "Epoch 5/20\n",
      "326/326 [==============================] - 135s 415ms/step - loss: 0.3437 - acc: 0.8585 - val_loss: 0.6715 - val_acc: 0.8750\n",
      "Epoch 6/20\n",
      "326/326 [==============================] - 124s 382ms/step - loss: 0.3264 - acc: 0.8658 - val_loss: 0.7211 - val_acc: 0.7500\n",
      "Epoch 7/20\n",
      "326/326 [==============================] - 121s 372ms/step - loss: 0.3283 - acc: 0.8633 - val_loss: 0.5480 - val_acc: 0.7500\n",
      "Epoch 8/20\n",
      "326/326 [==============================] - 120s 367ms/step - loss: 0.3214 - acc: 0.8645 - val_loss: 0.8256 - val_acc: 0.8125\n",
      "Epoch 9/20\n",
      "326/326 [==============================] - 116s 357ms/step - loss: 0.3208 - acc: 0.8717 - val_loss: 0.5286 - val_acc: 0.8125\n",
      "Epoch 10/20\n",
      "326/326 [==============================] - 619s 2s/step - loss: 0.3208 - acc: 0.8671 - val_loss: 1.0013 - val_acc: 0.7500\n",
      "Epoch 11/20\n",
      "326/326 [==============================] - 109s 334ms/step - loss: 0.3259 - acc: 0.8618 - val_loss: 0.6576 - val_acc: 0.7500\n",
      "Epoch 12/20\n",
      "326/326 [==============================] - 104s 318ms/step - loss: 0.3214 - acc: 0.8704 - val_loss: 1.0233 - val_acc: 0.6875\n",
      "Epoch 13/20\n",
      "326/326 [==============================] - 101s 310ms/step - loss: 0.3251 - acc: 0.8633 - val_loss: 0.5954 - val_acc: 0.8125\n",
      "Epoch 14/20\n",
      "326/326 [==============================] - 100s 306ms/step - loss: 0.3314 - acc: 0.8673 - val_loss: 0.7524 - val_acc: 0.7500\n",
      "Epoch 15/20\n",
      "326/326 [==============================] - 101s 311ms/step - loss: 0.3281 - acc: 0.8714 - val_loss: 0.6050 - val_acc: 0.7500\n",
      "Epoch 16/20\n",
      "326/326 [==============================] - 4840s 15s/step - loss: 0.3199 - acc: 0.8744 - val_loss: 0.6197 - val_acc: 0.6875\n",
      "Epoch 17/20\n",
      "326/326 [==============================] - 14512s 45s/step - loss: 0.3137 - acc: 0.8752 - val_loss: 0.6020 - val_acc: 0.7500\n",
      "Epoch 18/20\n",
      "326/326 [==============================] - 14540s 45s/step - loss: 0.3155 - acc: 0.8723 - val_loss: 0.6905 - val_acc: 0.7500\n",
      "Epoch 19/20\n",
      "326/326 [==============================] - 4256s 13s/step - loss: 0.3319 - acc: 0.8685 - val_loss: 0.5195 - val_acc: 0.8750\n",
      "Epoch 20/20\n",
      "326/326 [==============================] - 140s 429ms/step - loss: 0.4057 - acc: 0.8418 - val_loss: 0.4247 - val_acc: 0.6875\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train,\n",
    "                   steps_per_epoch=5216 // 16,\n",
    "                   epochs = 20,\n",
    "                   validation_data = test,\n",
    "                   validation_steps=800 // 16)\n",
    "model.save_weights('weights')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
