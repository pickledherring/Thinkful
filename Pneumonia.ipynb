{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "why you picked this data where you got it( intro slide) \n",
    "look at some of images (typical for class 1 and class 2 ) \n",
    "feature extraction (not required but you can use https://scikit-learn.org/stable/modules/feature_extraction.html) \n",
    "to explicitly get features to understand what are the features making up class 1 etc \n",
    "then model fitting \n",
    "you can have a table of all models fitted with the accuracy score, precision, recall f1 \n",
    "and discuss which one is winning (is type 1 worse than type 2 etc) \n",
    "then print out some examples where your model is making correct pred and incorrect pred \n",
    "then conclusions/next steps \n",
    "so in total you can have 10 slides for this\n",
    "with some appendix if you want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "import glob\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for directory, _, file in os.walk('data/chest_xray/train'):\n",
    "    # cutting the data in half because it takes too long to run these models on the full data\n",
    "    # grayscale to better fit in the RF and SVC models\n",
    "    for f in file[1::2]:\n",
    "        f = os.path.join(directory, f)\n",
    "        img = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            # resizing to (150, 150)\n",
    "            img = resize(img, (150, 150, 1))\n",
    "            img = np.asarray(img)\n",
    "            label=f.split('/')[-2]\n",
    "            X.append(img)\n",
    "            y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "for directory, _, file in os.walk('data/chest_xray/test'):\n",
    "    # not cutting this in half because the test set is already small\n",
    "    for f in file[1:]:\n",
    "        f = os.path.join(directory, f)\n",
    "        img = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = resize(img, (150, 150, 1))\n",
    "            img = np.asarray(img)\n",
    "            label=f.split('/')[-2]\n",
    "            X_test.append(img)\n",
    "            y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test = np.asarray(X), np.asarray(X_test)\n",
    "y, y_test = np.asarray(y), np.asarray(y_test)\n",
    "\n",
    "X_rf = []\n",
    "# flattening to a 1 dimensional array to feed into the RF and SVC models\n",
    "for i in range(len(X)):\n",
    "    a = X[i].flatten()\n",
    "    X_rf.append(a)\n",
    "    \n",
    "X_rf = np.asarray(X_rf)\n",
    "\n",
    "X_rf_test = []\n",
    "for i in range(len(X_test)):\n",
    "    a = X_test[i].flatten()\n",
    "    X_rf_test.append(a)\n",
    "    \n",
    "X_rf_test = np.asarray(X_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarizing\n",
    "for i in range(len(y)):\n",
    "    if y[i] == 'PNEUMONIA':\n",
    "        y[i] = 1\n",
    "    else:\n",
    "        y[i] = 0\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == 'PNEUMONIA':\n",
    "        y_test[i] = 1\n",
    "    else:\n",
    "        y_test[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.94552239 0.67294786]\n"
     ]
    }
   ],
   "source": [
    "# computing class weights. this data is imbalanced\n",
    "from sklearn.utils import class_weight\n",
    "y_labels = np.argmax(y)\n",
    "classweight = class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
    "print(classweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91954023 0.91254315 0.93317972]\n"
     ]
    }
   ],
   "source": [
    "rf = ensemble.RandomForestClassifier()\n",
    "rf.fit(X_rf, y)\n",
    "print(cross_val_score(rf, X_rf, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.792604501607717\n",
      "true negative: 115\n",
      "false negative: 118\n",
      "true positive: 378\n",
      "false positive: 11\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_rf_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_pred, y_test).ravel()\n",
    "accuracy = (tn + tp) / (tn + tp + fn + fp)\n",
    "print('accuracy: {}\\ntrue negative: {}\\nfalse negative: {}\\ntrue positive: {}\\nfalse positive: {}'\n",
    "      .format(accuracy, tn, fn, tp, fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92068966 0.89643268 0.90898618]\n",
      "accuracy: 0.7781350482315113\n",
      "true negative: 111\n",
      "false negative: 122\n",
      "true positive: 373\n",
      "false positive: 16\n"
     ]
    }
   ],
   "source": [
    "# employing class weights here\n",
    "rf = ensemble.RandomForestClassifier(class_weight = {'0':classweight[0], '1':classweight[1]})\n",
    "rf.fit(X_rf, y)\n",
    "print(cross_val_score(rf, X_rf, y))\n",
    "\n",
    "y_pred = rf.predict(X_rf_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_pred, y_test).ravel()\n",
    "accuracy = (tn + tp) / (tn + tp + fn + fp)\n",
    "print('accuracy: {}\\ntrue negative: {}\\nfalse negative: {}\\ntrue positive: {}\\nfalse positive: {}'\n",
    "      .format(accuracy, tn, fn, tp, fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does fairly poorly, giving equally likely true and false negatives. The high accuracy is primarily a result of the unbalanced nature of the samples. Sensitivity is our most important metric, and it, at least, it somewhat low. Oddly, class weight balancing appears to make this model perform worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7427652733118971\n",
      "true negative: 79\n",
      "false negative: 154\n",
      "true positive: 383\n",
      "false positive: 6\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_rf, y)\n",
    "y_pred = svc.predict(X_rf_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_pred, y_test).ravel()\n",
    "accuracy = (tn + tp) / (tn + tp + fn + fp)\n",
    "print('accuracy: {}\\ntrue negative: {}\\nfalse negative: {}\\ntrue positive: {}\\nfalse positive: {}'\n",
    "      .format(accuracy, tn, fn, tp, fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8263665594855305\n",
      "true negative: 149\n",
      "false negative: 84\n",
      "true positive: 365\n",
      "false positive: 24\n"
     ]
    }
   ],
   "source": [
    "# employing class weights here\n",
    "svc = SVC(class_weight = 'balanced')\n",
    "svc.fit(X_rf, y)\n",
    "y_pred = svc.predict(X_rf_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_pred, y_test).ravel()\n",
    "accuracy = (tn + tp) / (tn + tp + fn + fp)\n",
    "print('accuracy: {}\\ntrue negative: {}\\nfalse negative: {}\\ntrue positive: {}\\nfalse positive: {}'\n",
    "      .format(accuracy, tn, fn, tp, fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall accuracy is significantly higher, yet sensitivity is lower than the random forest model. Runtime is also significantly longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulating the data to give more robust results\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=.2,\n",
    "        height_shift_range=.2,\n",
    "        rescale=1/255,\n",
    "        shear_range=.2,\n",
    "        zoom_range=.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, 150, 150)\n",
    "else:\n",
    "    input_shape = (150, 150, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = datagen.flow_from_directory('data/chest_xray/train',\n",
    "                                   target_size=(150, 150),\n",
    "                                   batch_size=16,\n",
    "                                   class_mode='binary')\n",
    "\n",
    "test = test_datagen.flow_from_directory('data/chest_xray/test',\n",
    "                                   target_size=(150, 150),\n",
    "                                   batch_size=16,\n",
    "                                   class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "326/326 [==============================] - 95s 293ms/step - loss: 4.0965 - acc: 0.7429 - val_loss: 5.9784 - val_acc: 0.6250\n",
      "Epoch 2/5\n",
      "326/326 [==============================] - 92s 281ms/step - loss: 4.0906 - acc: 0.7429 - val_loss: 5.9784 - val_acc: 0.6250\n",
      "Epoch 3/5\n",
      "326/326 [==============================] - 90s 277ms/step - loss: 4.0941 - acc: 0.7425 - val_loss: 5.9784 - val_acc: 0.6250\n",
      "Epoch 4/5\n",
      "326/326 [==============================] - 89s 274ms/step - loss: 4.0991 - acc: 0.7429 - val_loss: 5.9784 - val_acc: 0.6250\n",
      "Epoch 5/5\n",
      "326/326 [==============================] - 89s 273ms/step - loss: 4.0850 - acc: 0.7429 - val_loss: 5.9784 - val_acc: 0.6250\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train,\n",
    "                   steps_per_epoch=5216 // 16,\n",
    "                   epochs = 5,\n",
    "                   validation_data = test,\n",
    "                   validation_steps=624 // 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "39/39 [==============================] - 5s 133ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.978394523645059, 0.625]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For inputting test images in color and for the last model\n",
    "X = []\n",
    "y = []\n",
    "for directory, _, file in os.walk('data/chest_xray/train'):\n",
    "    for f in file[1::2]:\n",
    "        f = os.path.join(directory, f)\n",
    "        img = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "        if img is not None:\n",
    "            img = resize(img, (150, 150, 3))\n",
    "            img = np.asarray(img)\n",
    "            label=f.split('/')[-2]\n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "            \n",
    "X_test = []\n",
    "y_test = []\n",
    "for directory, _, file in os.walk('data/chest_xray/test'):\n",
    "    for f in file[1:]:\n",
    "        f = os.path.join(directory, f)\n",
    "        img = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "        if img is not None:\n",
    "            img = resize(img, (150, 150, 3))\n",
    "            img = np.asarray(img)\n",
    "            label=f.split('/')[-2]\n",
    "            X_test.append(img)\n",
    "            y_test.append(label)\n",
    "            \n",
    "X, X_test = np.asarray(X), np.asarray(X_test)\n",
    "y, y_test = np.asarray(y), np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y)):\n",
    "    if y[i] == 'PNEUMONIA':\n",
    "        y[i] = 1\n",
    "    else:\n",
    "        y[i] = 0\n",
    "\n",
    "for i in range(len(y_test2)):\n",
    "    if y_test[i] == 'PNEUMONIA':\n",
    "        y_test[i] = 1\n",
    "    else:\n",
    "        y_test[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6254019292604501\n",
      "true negative: 0\n",
      "false negative: 233\n",
      "true positive: 389\n",
      "false positive: 0\n"
     ]
    }
   ],
   "source": [
    "y = [int(i) for i in y]\n",
    "y_test = [int(i) for i in y_test]\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_pred, y_test).ravel()\n",
    "accuracy = (tn + tp) / (tn + tp + fn + fp)\n",
    "print('accuracy: {}\\ntrue negative: {}\\nfalse negative: {}\\ntrue positive: {}\\nfalse positive: {}'\n",
    "      .format(accuracy, tn, fn, tp, fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dense network has one 64 feature layer and drops out half the data to avoid overfitting. This model only ended up predicting 1s, so we'll weight it as well and see if that changes anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              weighted_metrics=['categorical_accuracy'],\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "326/326 [==============================] - 86s 262ms/step - loss: 4.0950 - acc: 0.7410 - weighted_categorical_accuracy: 1.0000 - val_loss: 5.9784 - val_acc: 0.6250 - val_weighted_categorical_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "326/326 [==============================] - 82s 252ms/step - loss: 4.0988 - acc: 0.7429 - weighted_categorical_accuracy: 1.0000 - val_loss: 5.9784 - val_acc: 0.6250 - val_weighted_categorical_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "326/326 [==============================] - 82s 251ms/step - loss: 4.0987 - acc: 0.7429 - weighted_categorical_accuracy: 1.0000 - val_loss: 5.9784 - val_acc: 0.6250 - val_weighted_categorical_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "326/326 [==============================] - 82s 252ms/step - loss: 4.0987 - acc: 0.7429 - weighted_categorical_accuracy: 1.0000 - val_loss: 5.9784 - val_acc: 0.6250 - val_weighted_categorical_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "326/326 [==============================] - 82s 252ms/step - loss: 4.0989 - acc: 0.7429 - weighted_categorical_accuracy: 1.0000 - val_loss: 5.9784 - val_acc: 0.6250 - val_weighted_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14f519390>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train,\n",
    "                   steps_per_epoch=5216 // 16,\n",
    "                   epochs = 5,\n",
    "                   validation_data = test,\n",
    "                   validation_steps=624 // 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6254019292604501\n",
      "true negative: 0\n",
      "false negative: 233\n",
      "true positive: 389\n",
      "false positive: 0\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_pred, y_test).ravel()\n",
    "accuracy = (tn + tp) / (tn + tp + fn + fp)\n",
    "print('accuracy: {}\\ntrue negative: {}\\nfalse negative: {}\\ntrue positive: {}\\nfalse positive: {}'\n",
    "      .format(accuracy, tn, fn, tp, fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It has fairly miserable performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27\n",
      "326/326 [==============================] - 107s 329ms/step - loss: 0.5246 - acc: 0.7548 - val_loss: 0.7511 - val_acc: 0.6218\n",
      "Epoch 2/27\n",
      "326/326 [==============================] - 102s 313ms/step - loss: 0.4611 - acc: 0.7655 - val_loss: 0.6494 - val_acc: 0.6394\n",
      "Epoch 3/27\n",
      "326/326 [==============================] - 103s 315ms/step - loss: 0.4221 - acc: 0.7860 - val_loss: 0.4826 - val_acc: 0.7083\n",
      "Epoch 4/27\n",
      "326/326 [==============================] - 103s 315ms/step - loss: 0.3850 - acc: 0.8190 - val_loss: 0.4900 - val_acc: 0.7452\n",
      "Epoch 5/27\n",
      "326/326 [==============================] - 102s 313ms/step - loss: 0.3730 - acc: 0.8259 - val_loss: 0.8272 - val_acc: 0.6827\n",
      "Epoch 6/27\n",
      "326/326 [==============================] - 102s 313ms/step - loss: 0.3538 - acc: 0.8367 - val_loss: 0.6281 - val_acc: 0.7324\n",
      "Epoch 7/27\n",
      "326/326 [==============================] - 102s 314ms/step - loss: 0.3434 - acc: 0.8439 - val_loss: 0.4612 - val_acc: 0.7997\n",
      "Epoch 8/27\n",
      "326/326 [==============================] - 1278s 4s/step - loss: 0.3208 - acc: 0.8579 - val_loss: 0.3857 - val_acc: 0.8109\n",
      "Epoch 9/27\n",
      "326/326 [==============================] - 105s 323ms/step - loss: 0.3153 - acc: 0.8610 - val_loss: 0.3752 - val_acc: 0.8333\n",
      "Epoch 10/27\n",
      "326/326 [==============================] - 107s 328ms/step - loss: 0.2987 - acc: 0.8650 - val_loss: 0.3850 - val_acc: 0.8237\n",
      "Epoch 11/27\n",
      "326/326 [==============================] - 104s 320ms/step - loss: 0.2896 - acc: 0.8692 - val_loss: 0.3677 - val_acc: 0.8349\n",
      "Epoch 12/27\n",
      "326/326 [==============================] - 105s 323ms/step - loss: 0.2920 - acc: 0.8773 - val_loss: 0.3937 - val_acc: 0.8045\n",
      "Epoch 13/27\n",
      "326/326 [==============================] - 104s 318ms/step - loss: 0.2864 - acc: 0.8762 - val_loss: 0.3585 - val_acc: 0.8269\n",
      "Epoch 14/27\n",
      "326/326 [==============================] - 105s 321ms/step - loss: 0.2767 - acc: 0.8821 - val_loss: 0.3671 - val_acc: 0.8590\n",
      "Epoch 15/27\n",
      "326/326 [==============================] - 104s 320ms/step - loss: 0.2664 - acc: 0.8838 - val_loss: 0.3833 - val_acc: 0.8381\n",
      "Epoch 16/27\n",
      "326/326 [==============================] - 105s 323ms/step - loss: 0.2614 - acc: 0.8871 - val_loss: 0.3416 - val_acc: 0.8526\n",
      "Epoch 17/27\n",
      "326/326 [==============================] - 104s 319ms/step - loss: 0.2532 - acc: 0.8986 - val_loss: 0.3273 - val_acc: 0.8478\n",
      "Epoch 18/27\n",
      "326/326 [==============================] - 106s 327ms/step - loss: 0.2462 - acc: 0.8988 - val_loss: 0.4153 - val_acc: 0.8285\n",
      "Epoch 19/27\n",
      "326/326 [==============================] - 106s 324ms/step - loss: 0.2486 - acc: 0.8970 - val_loss: 0.3691 - val_acc: 0.8205\n",
      "Epoch 20/27\n",
      "326/326 [==============================] - 106s 324ms/step - loss: 0.2466 - acc: 0.8974 - val_loss: 0.3637 - val_acc: 0.8381\n",
      "Epoch 21/27\n",
      "326/326 [==============================] - 105s 322ms/step - loss: 0.2372 - acc: 0.9032 - val_loss: 0.3490 - val_acc: 0.8301\n",
      "Epoch 22/27\n",
      "326/326 [==============================] - 105s 323ms/step - loss: 0.2274 - acc: 0.9022 - val_loss: 0.3687 - val_acc: 0.8413\n",
      "Epoch 23/27\n",
      "326/326 [==============================] - 105s 321ms/step - loss: 0.2394 - acc: 0.9003 - val_loss: 0.5317 - val_acc: 0.8029\n",
      "Epoch 24/27\n",
      "326/326 [==============================] - 106s 326ms/step - loss: 0.2328 - acc: 0.9086 - val_loss: 0.4090 - val_acc: 0.8542\n",
      "Epoch 25/27\n",
      "326/326 [==============================] - 105s 323ms/step - loss: 0.2301 - acc: 0.9070 - val_loss: 0.3771 - val_acc: 0.8478\n",
      "Epoch 26/27\n",
      "326/326 [==============================] - 104s 320ms/step - loss: 0.2194 - acc: 0.9080 - val_loss: 0.4096 - val_acc: 0.8365\n",
      "Epoch 27/27\n",
      "326/326 [==============================] - 106s 325ms/step - loss: 0.2148 - acc: 0.9101 - val_loss: 0.3972 - val_acc: 0.8494\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train,\n",
    "                   steps_per_epoch=5216 // 16,\n",
    "                   epochs = 27,\n",
    "                   validation_data = test,\n",
    "                   validation_steps=624 // 16)\n",
    "model.save_weights('weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8183279742765274\n",
      "true negative: 129\n",
      "false negative: 104\n",
      "true positive: 380\n",
      "false positive: 9\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "# binarizing output\n",
    "y_binary_pred = []\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] >= .5:\n",
    "        y_binary_pred.append(1)\n",
    "    else:\n",
    "        y_binary_pred.append(0)\n",
    "        \n",
    "tn, fp, fn, tp = confusion_matrix(y_binary_pred, y_test).ravel()\n",
    "accuracy = (tn + tp) / (tn + tp + fn + fp)\n",
    "print('accuracy: {}\\ntrue negative: {}\\nfalse negative: {}\\ntrue positive: {}\\nfalse positive: {}'\n",
    "      .format(accuracy, tn, fn, tp, fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our CNN model uses three convolutional neural networks chained together with pooling layers, and round it out with the same two dense layers around a 50% dropout as before. Performance is better, but still falls short of ever being useful. Weighting it (weighted modeled not included) didn't appear to help, but the unweighted model has a fairly low number of errors, especially type II errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 16386     \n",
      "=================================================================\n",
      "Total params: 14,731,074\n",
      "Trainable params: 14,731,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(include_top=False, input_shape=(150, 150, 3))\n",
    "# binarizing our output\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=model.input, outputs=x)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing the top 18 layers to expedite this training\n",
    "for layer in model.layers[0:18]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 16386     \n",
      "=================================================================\n",
      "Total params: 14,731,074\n",
      "Trainable params: 16,386\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2607 samples, validate on 622 samples\n",
      "Epoch 1/30\n",
      "2607/2607 [==============================] - 108s 42ms/step - loss: 0.5086 - acc: 0.7729 - val_loss: 0.4870 - val_acc: 0.7170\n",
      "Epoch 2/30\n",
      "2607/2607 [==============================] - 96s 37ms/step - loss: 0.2099 - acc: 0.9214 - val_loss: 0.3940 - val_acc: 0.8006\n",
      "Epoch 3/30\n",
      "2607/2607 [==============================] - 97s 37ms/step - loss: 0.1599 - acc: 0.9356 - val_loss: 0.3579 - val_acc: 0.8376\n",
      "Epoch 4/30\n",
      "2607/2607 [==============================] - 98s 38ms/step - loss: 0.1300 - acc: 0.9567 - val_loss: 0.3816 - val_acc: 0.8280\n",
      "Epoch 5/30\n",
      "2607/2607 [==============================] - 98s 38ms/step - loss: 0.1167 - acc: 0.9590 - val_loss: 0.5447 - val_acc: 0.7637\n",
      "Epoch 6/30\n",
      "2607/2607 [==============================] - 98s 38ms/step - loss: 0.1097 - acc: 0.9624 - val_loss: 0.4846 - val_acc: 0.7894\n",
      "Epoch 7/30\n",
      "2607/2607 [==============================] - 102s 39ms/step - loss: 0.0984 - acc: 0.9666 - val_loss: 0.4518 - val_acc: 0.8055\n",
      "Epoch 8/30\n",
      "2607/2607 [==============================] - 103s 40ms/step - loss: 0.1027 - acc: 0.9628 - val_loss: 0.3428 - val_acc: 0.8569\n",
      "Epoch 9/30\n",
      "2607/2607 [==============================] - 99s 38ms/step - loss: 0.0888 - acc: 0.9720 - val_loss: 0.4057 - val_acc: 0.8296\n",
      "Epoch 10/30\n",
      "2607/2607 [==============================] - 98s 38ms/step - loss: 0.0842 - acc: 0.9735 - val_loss: 0.4548 - val_acc: 0.8167\n",
      "Epoch 11/30\n",
      "2607/2607 [==============================] - 101s 39ms/step - loss: 0.0784 - acc: 0.9774 - val_loss: 0.5765 - val_acc: 0.7717\n",
      "Epoch 12/30\n",
      "2607/2607 [==============================] - 97s 37ms/step - loss: 0.0758 - acc: 0.9770 - val_loss: 0.5297 - val_acc: 0.7894\n",
      "Epoch 13/30\n",
      "2607/2607 [==============================] - 97s 37ms/step - loss: 0.0693 - acc: 0.9801 - val_loss: 0.4663 - val_acc: 0.8151\n",
      "Epoch 14/30\n",
      "2607/2607 [==============================] - 96s 37ms/step - loss: 0.0689 - acc: 0.9766 - val_loss: 0.4382 - val_acc: 0.8248\n",
      "Epoch 15/30\n",
      "2607/2607 [==============================] - 97s 37ms/step - loss: 0.0638 - acc: 0.9820 - val_loss: 0.5280 - val_acc: 0.7990\n",
      "Epoch 16/30\n",
      "2607/2607 [==============================] - 98s 37ms/step - loss: 0.0607 - acc: 0.9843 - val_loss: 0.4636 - val_acc: 0.8199\n",
      "Epoch 17/30\n",
      "2607/2607 [==============================] - 99s 38ms/step - loss: 0.0595 - acc: 0.9843 - val_loss: 0.4809 - val_acc: 0.8151\n",
      "Epoch 18/30\n",
      "2607/2607 [==============================] - 97s 37ms/step - loss: 0.0568 - acc: 0.9847 - val_loss: 0.5277 - val_acc: 0.7990\n",
      "Epoch 19/30\n",
      "2607/2607 [==============================] - 97s 37ms/step - loss: 0.0542 - acc: 0.9866 - val_loss: 0.4805 - val_acc: 0.8151\n",
      "Epoch 20/30\n",
      "2607/2607 [==============================] - 96s 37ms/step - loss: 0.0540 - acc: 0.9873 - val_loss: 0.5656 - val_acc: 0.7862\n",
      "Epoch 21/30\n",
      "2607/2607 [==============================] - 97s 37ms/step - loss: 0.0512 - acc: 0.9850 - val_loss: 0.6244 - val_acc: 0.7765\n",
      "Epoch 22/30\n",
      "2607/2607 [==============================] - 98s 37ms/step - loss: 0.0491 - acc: 0.9881 - val_loss: 0.5142 - val_acc: 0.8119\n",
      "Epoch 23/30\n",
      "2607/2607 [==============================] - 98s 37ms/step - loss: 0.0488 - acc: 0.9873 - val_loss: 0.4868 - val_acc: 0.8215\n",
      "Epoch 24/30\n",
      "2607/2607 [==============================] - 101s 39ms/step - loss: 0.0467 - acc: 0.9877 - val_loss: 0.5617 - val_acc: 0.7942\n",
      "Epoch 25/30\n",
      "2607/2607 [==============================] - 98s 38ms/step - loss: 0.0446 - acc: 0.9896 - val_loss: 0.5317 - val_acc: 0.8087\n",
      "Epoch 26/30\n",
      "2607/2607 [==============================] - 97s 37ms/step - loss: 0.0430 - acc: 0.9900 - val_loss: 0.5370 - val_acc: 0.8087\n",
      "Epoch 27/30\n",
      "2607/2607 [==============================] - 97s 37ms/step - loss: 0.0422 - acc: 0.9908 - val_loss: 0.5144 - val_acc: 0.8151\n",
      "Epoch 28/30\n",
      "2607/2607 [==============================] - 97s 37ms/step - loss: 0.0412 - acc: 0.9912 - val_loss: 0.6457 - val_acc: 0.7781\n",
      "Epoch 29/30\n",
      "2607/2607 [==============================] - 97s 37ms/step - loss: 0.0395 - acc: 0.9900 - val_loss: 0.6366 - val_acc: 0.7797\n",
      "Epoch 30/30\n",
      "2607/2607 [==============================] - 97s 37ms/step - loss: 0.0382 - acc: 0.9916 - val_loss: 0.6148 - val_acc: 0.7862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15751c510>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y2 = y\n",
    "y_test2 = y_test\n",
    "y2 = to_categorical(y2)\n",
    "y_test2 = to_categorical(y_test2)\n",
    "model.fit(X, y2,\n",
    "          batch_size = 200,\n",
    "          epochs = 30,\n",
    "          validation_data = (X_test, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-9589e6ff7ef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_binary_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0my_binary_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "# binarizing output\n",
    "y_binary_pred = []\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] >= .5:\n",
    "        y_binary_pred.append(1)\n",
    "    else:\n",
    "        y_binary_pred.append(0)\n",
    "        \n",
    "tn, fp, fn, tp = confusion_matrix(y_pred, y_test2).ravel()\n",
    "accuracy = (tn + tp) / (tn + tp + fn + fp)\n",
    "print('accuracy: {}\\ntrue negative: {}\\nfalse negative: {}\\ntrue positive: {}\\nfalse positive: {}'\n",
    "      .format(accuracy, tn, fn, tp, fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.2564187e-05, 9.9990737e-01],\n",
       "       [2.9377057e-04, 9.9970621e-01],\n",
       "       [8.2008431e-05, 9.9991798e-01],\n",
       "       ...,\n",
       "       [2.7759981e-01, 7.2240019e-01],\n",
       "       [6.9250260e-03, 9.9307501e-01],\n",
       "       [1.2869163e-03, 9.9871314e-01]], dtype=float32)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs significanty better, but it overfits and still leaves us with quite a lot of type I error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're taking the sum of y_pred and y_test2 to find examples of misclassified and properly classified images.\n",
    "# Since the output is binary, 1s will indicate false predictions, and 0s and 2s will indicate true ones.\n",
    "\n",
    "y_tot = np.add(y_pred, y_test2)\n",
    "print(y_tot[y_tot == 1].index)\n",
    "print(y_tot)\n",
    "plt.imshow(X_test[5])\n",
    "print(y_tot[y_tot == 2].index)\n",
    "plt.imshow(X_test[100])\n",
    "print(y_tot[y_tot == 0].index)\n",
    "plt.imshow(X_test[300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
